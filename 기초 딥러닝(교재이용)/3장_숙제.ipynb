{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 뉴스 기사 분류: 다중 분류 문제 </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import reuters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\lee36\\lib\\site-packages\\keras\\datasets\\reuters.py:85: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
      "D:\\anaconda\\envs\\lee36\\lib\\site-packages\\keras\\datasets\\reuters.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    }
   ],
   "source": [
    "# data load\n",
    "(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequences in enumerate(sequences):\n",
    "        results[i, sequences]= 1.\n",
    "    return results\n",
    "\n",
    "x_train = vectorize_sequences(train_data)\n",
    "x_test = vectorize_sequences(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "one_hot_train_labels = to_categorical(train_labels)\n",
    "one_hot_test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 정의\n",
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation ='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(64, activation ='relu'))\n",
    "model.add(layers.Dense(46, activation ='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'rmsprop',\n",
    "             loss = 'categorical_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = x_train[:1000]\n",
    "partial_x_train = x_train[1000:]\n",
    "\n",
    "y_val= one_hot_train_labels[:1000]\n",
    "partial_y_train = one_hot_train_labels[1000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/9\n",
      "7982/7982 [==============================] - 3s 401us/step - loss: 2.6073 - accuracy: 0.5296 - val_loss: 1.7140 - val_accuracy: 0.6490\n",
      "Epoch 2/9\n",
      "7982/7982 [==============================] - 1s 93us/step - loss: 1.4076 - accuracy: 0.7114 - val_loss: 1.3232 - val_accuracy: 0.7260\n",
      "Epoch 3/9\n",
      "7982/7982 [==============================] - 1s 104us/step - loss: 1.0616 - accuracy: 0.7690 - val_loss: 1.1676 - val_accuracy: 0.7560\n",
      "Epoch 4/9\n",
      "7982/7982 [==============================] - 1s 120us/step - loss: 0.8436 - accuracy: 0.8163 - val_loss: 1.0736 - val_accuracy: 0.7740\n",
      "Epoch 5/9\n",
      "7982/7982 [==============================] - 1s 90us/step - loss: 0.6826 - accuracy: 0.8513 - val_loss: 1.0340 - val_accuracy: 0.7670\n",
      "Epoch 6/9\n",
      "7982/7982 [==============================] - 1s 116us/step - loss: 0.5481 - accuracy: 0.8849 - val_loss: 0.9562 - val_accuracy: 0.8050\n",
      "Epoch 7/9\n",
      "7982/7982 [==============================] - 1s 106us/step - loss: 0.4466 - accuracy: 0.9057 - val_loss: 0.9416 - val_accuracy: 0.8080\n",
      "Epoch 8/9\n",
      "7982/7982 [==============================] - 1s 104us/step - loss: 0.3607 - accuracy: 0.9232 - val_loss: 0.9564 - val_accuracy: 0.8050\n",
      "Epoch 9/9\n",
      "7982/7982 [==============================] - 1s 126us/step - loss: 0.3006 - accuracy: 0.9365 - val_loss: 0.9108 - val_accuracy: 0.8150\n",
      "2246/2246 [==============================] - 0s 198us/step\n"
     ]
    }
   ],
   "source": [
    "model.fit(partial_x_train,\n",
    "         partial_y_train,\n",
    "         epochs=9,\n",
    "         batch_size = 512,\n",
    "         validation_data = (x_val,y_val))\n",
    "results = model.evaluate(x_test,one_hot_test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9918616571706634, 0.784060537815094]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(prediction[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/9\n",
      "7982/7982 [==============================] - 1s 94us/step - loss: 2.8272 - accuracy: 0.5074 - val_loss: 1.8025 - val_accuracy: 0.6490\n",
      "Epoch 2/9\n",
      "7982/7982 [==============================] - 1s 78us/step - loss: 1.4804 - accuracy: 0.6991 - val_loss: 1.3352 - val_accuracy: 0.7110\n",
      "Epoch 3/9\n",
      "7982/7982 [==============================] - 1s 81us/step - loss: 1.1009 - accuracy: 0.7581 - val_loss: 1.1755 - val_accuracy: 0.7420\n",
      "Epoch 4/9\n",
      "7982/7982 [==============================] - 1s 80us/step - loss: 0.8716 - accuracy: 0.8097 - val_loss: 1.0917 - val_accuracy: 0.7670\n",
      "Epoch 5/9\n",
      "7982/7982 [==============================] - 1s 101us/step - loss: 0.6928 - accuracy: 0.8463 - val_loss: 1.0166 - val_accuracy: 0.7800\n",
      "Epoch 6/9\n",
      "7982/7982 [==============================] - 1s 89us/step - loss: 0.5544 - accuracy: 0.8782 - val_loss: 0.9960 - val_accuracy: 0.7970\n",
      "Epoch 7/9\n",
      "7982/7982 [==============================] - 1s 77us/step - loss: 0.4421 - accuracy: 0.9043 - val_loss: 0.9823 - val_accuracy: 0.8050\n",
      "Epoch 8/9\n",
      "7982/7982 [==============================] - 1s 79us/step - loss: 0.3628 - accuracy: 0.9237 - val_loss: 1.0046 - val_accuracy: 0.8050\n",
      "Epoch 9/9\n",
      "7982/7982 [==============================] - 1s 77us/step - loss: 0.2980 - accuracy: 0.9350 - val_loss: 0.9890 - val_accuracy: 0.8130\n",
      "2246/2246 [==============================] - 0s 136us/step\n",
      "[1.0749854822829696, 0.7827248573303223]\n"
     ]
    }
   ],
   "source": [
    "# 1\n",
    "# 3개 은닉층 \n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation ='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(64, activation ='relu'))\n",
    "model.add(layers.Dense(64, activation ='relu'))\n",
    "model.add(layers.Dense(46, activation ='softmax'))\n",
    "\n",
    "model.compile(optimizer = 'rmsprop',\n",
    "             loss = 'categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(partial_x_train,\n",
    "         partial_y_train,\n",
    "         epochs=9,\n",
    "         batch_size = 512,\n",
    "         validation_data = (x_val,y_val))\n",
    "results = model.evaluate(x_test,one_hot_test_labels)\n",
    "print(results)\\\n",
    "# 78.27%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/9\n",
      "7982/7982 [==============================] - 1s 88us/step - loss: 2.1807 - accuracy: 0.5709 - val_loss: 1.3923 - val_accuracy: 0.6910\n",
      "Epoch 2/9\n",
      "7982/7982 [==============================] - 1s 86us/step - loss: 1.1025 - accuracy: 0.7581 - val_loss: 1.1022 - val_accuracy: 0.7520\n",
      "Epoch 3/9\n",
      "7982/7982 [==============================] - 1s 108us/step - loss: 0.7903 - accuracy: 0.8289 - val_loss: 0.9915 - val_accuracy: 0.7850\n",
      "Epoch 4/9\n",
      "7982/7982 [==============================] - 1s 96us/step - loss: 0.5622 - accuracy: 0.8837 - val_loss: 0.9062 - val_accuracy: 0.8110\n",
      "Epoch 5/9\n",
      "7982/7982 [==============================] - 1s 80us/step - loss: 0.4269 - accuracy: 0.9093 - val_loss: 0.9540 - val_accuracy: 0.7890\n",
      "Epoch 6/9\n",
      "7982/7982 [==============================] - 1s 83us/step - loss: 0.3091 - accuracy: 0.9334 - val_loss: 0.8654 - val_accuracy: 0.8180\n",
      "Epoch 7/9\n",
      "7982/7982 [==============================] - 1s 85us/step - loss: 0.2556 - accuracy: 0.9417 - val_loss: 0.8694 - val_accuracy: 0.8300\n",
      "Epoch 8/9\n",
      "7982/7982 [==============================] - 1s 80us/step - loss: 0.2094 - accuracy: 0.9493 - val_loss: 0.8996 - val_accuracy: 0.8180\n",
      "Epoch 9/9\n",
      "7982/7982 [==============================] - 1s 81us/step - loss: 0.1834 - accuracy: 0.9528 - val_loss: 0.9356 - val_accuracy: 0.8180\n",
      "2246/2246 [==============================] - 0s 132us/step\n",
      "[1.0176628141241846, 0.7947462201118469]\n"
     ]
    }
   ],
   "source": [
    "# 2 \n",
    "# 128 은닉수 \n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(128, activation ='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(128, activation ='relu'))\n",
    "model.add(layers.Dense(46, activation ='softmax'))\n",
    "\n",
    "model.compile(optimizer = 'rmsprop',\n",
    "             loss = 'categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(partial_x_train,\n",
    "         partial_y_train,\n",
    "         epochs=9,\n",
    "         batch_size = 512,\n",
    "         validation_data = (x_val,y_val))\n",
    "results = model.evaluate(x_test,one_hot_test_labels)\n",
    "print(results)\n",
    "# 79.4%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/9\n",
      "7982/7982 [==============================] - 1s 102us/step - loss: 2.2521 - accuracy: 0.5132 - val_loss: 1.4519 - val_accuracy: 0.6520\n",
      "Epoch 2/9\n",
      "7982/7982 [==============================] - 1s 85us/step - loss: 1.2093 - accuracy: 0.7270 - val_loss: 1.1789 - val_accuracy: 0.7290\n",
      "Epoch 3/9\n",
      "7982/7982 [==============================] - 1s 79us/step - loss: 0.8822 - accuracy: 0.7972 - val_loss: 1.0387 - val_accuracy: 0.7710\n",
      "Epoch 4/9\n",
      "7982/7982 [==============================] - 1s 81us/step - loss: 0.6737 - accuracy: 0.8458 - val_loss: 1.0098 - val_accuracy: 0.7780\n",
      "Epoch 5/9\n",
      "7982/7982 [==============================] - 1s 86us/step - loss: 0.4743 - accuracy: 0.8926 - val_loss: 1.1639 - val_accuracy: 0.7470\n",
      "Epoch 6/9\n",
      "7982/7982 [==============================] - 1s 105us/step - loss: 0.3499 - accuracy: 0.9270 - val_loss: 0.9668 - val_accuracy: 0.8010\n",
      "Epoch 7/9\n",
      "7982/7982 [==============================] - 1s 88us/step - loss: 0.2874 - accuracy: 0.9362 - val_loss: 0.9567 - val_accuracy: 0.8060\n",
      "Epoch 8/9\n",
      "7982/7982 [==============================] - 1s 83us/step - loss: 0.2126 - accuracy: 0.9470 - val_loss: 0.9932 - val_accuracy: 0.8030\n",
      "Epoch 9/9\n",
      "7982/7982 [==============================] - 1s 89us/step - loss: 0.2064 - accuracy: 0.9458 - val_loss: 0.9772 - val_accuracy: 0.8150\n",
      "2246/2246 [==============================] - 0s 130us/step\n",
      "[1.0956046375332404, 0.7960819005966187]\n"
     ]
    }
   ],
   "source": [
    "# 3\n",
    "# 1 + 2  \n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(128, activation ='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(128, activation ='relu'))\n",
    "model.add(layers.Dense(128, activation ='relu'))\n",
    "model.add(layers.Dense(46, activation ='softmax'))\n",
    "\n",
    "model.compile(optimizer = 'rmsprop',\n",
    "             loss = 'categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(partial_x_train,\n",
    "         partial_y_train,\n",
    "         epochs=9,\n",
    "         batch_size = 512,\n",
    "         validation_data = (x_val,y_val))\n",
    "results = model.evaluate(x_test,one_hot_test_labels)\n",
    "print(results)\n",
    "# 79.6%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/9\n",
      "7982/7982 [==============================] - 1s 98us/step - loss: 2.5202 - accuracy: 0.3782 - val_loss: 1.7088 - val_accuracy: 0.5550\n",
      "Epoch 2/9\n",
      "7982/7982 [==============================] - 1s 81us/step - loss: 1.5392 - accuracy: 0.6069 - val_loss: 1.3915 - val_accuracy: 0.6850\n",
      "Epoch 3/9\n",
      "7982/7982 [==============================] - 1s 92us/step - loss: 1.1892 - accuracy: 0.7187 - val_loss: 1.2524 - val_accuracy: 0.7060\n",
      "Epoch 4/9\n",
      "7982/7982 [==============================] - 1s 90us/step - loss: 0.9583 - accuracy: 0.7663 - val_loss: 1.1739 - val_accuracy: 0.7510\n",
      "Epoch 5/9\n",
      "7982/7982 [==============================] - 1s 88us/step - loss: 0.7666 - accuracy: 0.8113 - val_loss: 1.2755 - val_accuracy: 0.7260\n",
      "Epoch 6/9\n",
      "7982/7982 [==============================] - 1s 89us/step - loss: 0.6418 - accuracy: 0.8369 - val_loss: 1.0974 - val_accuracy: 0.7600\n",
      "Epoch 7/9\n",
      "7982/7982 [==============================] - 1s 84us/step - loss: 0.4827 - accuracy: 0.8758 - val_loss: 1.1155 - val_accuracy: 0.7750\n",
      "Epoch 8/9\n",
      "7982/7982 [==============================] - 1s 88us/step - loss: 0.4360 - accuracy: 0.8934 - val_loss: 1.1747 - val_accuracy: 0.7750\n",
      "Epoch 9/9\n",
      "7982/7982 [==============================] - 1s 87us/step - loss: 0.3806 - accuracy: 0.9027 - val_loss: 1.1120 - val_accuracy: 0.7920\n",
      "2246/2246 [==============================] - 0s 133us/step\n",
      "[1.2809263398789552, 0.767141580581665]\n"
     ]
    }
   ],
   "source": [
    "# 4\n",
    "# 6개 유닛층 (128 유닛 수)\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(128, activation ='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(128, activation ='relu'))\n",
    "model.add(layers.Dense(128, activation ='relu'))\n",
    "model.add(layers.Dense(128, activation ='relu'))\n",
    "model.add(layers.Dense(128, activation ='relu'))\n",
    "model.add(layers.Dense(128, activation ='relu'))\n",
    "model.add(layers.Dense(46, activation ='softmax'))\n",
    "\n",
    "model.compile(optimizer = 'rmsprop',\n",
    "             loss = 'categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(partial_x_train,\n",
    "         partial_y_train,\n",
    "         epochs=9,\n",
    "         batch_size = 512,\n",
    "         validation_data = (x_val,y_val))\n",
    "results = model.evaluate(x_test,one_hot_test_labels)\n",
    "print(results)\n",
    "# 76.71%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/9\n",
      "7982/7982 [==============================] - 3s 328us/step - loss: 2.4553 - accuracy: 0.4371 - val_loss: 1.6885 - val_accuracy: 0.5580\n",
      "Epoch 2/9\n",
      "7982/7982 [==============================] - 1s 100us/step - loss: 1.4226 - accuracy: 0.6501 - val_loss: 1.6331 - val_accuracy: 0.6050\n",
      "Epoch 3/9\n",
      "7982/7982 [==============================] - 1s 96us/step - loss: 1.1379 - accuracy: 0.7151 - val_loss: 1.2137 - val_accuracy: 0.7110\n",
      "Epoch 4/9\n",
      "7982/7982 [==============================] - 1s 91us/step - loss: 0.9016 - accuracy: 0.7607 - val_loss: 1.2779 - val_accuracy: 0.7290\n",
      "Epoch 5/9\n",
      "7982/7982 [==============================] - 1s 89us/step - loss: 0.6849 - accuracy: 0.8254 - val_loss: 1.1307 - val_accuracy: 0.7580\n",
      "Epoch 6/9\n",
      "7982/7982 [==============================] - 1s 97us/step - loss: 0.6791 - accuracy: 0.8236 - val_loss: 1.0674 - val_accuracy: 0.7810\n",
      "Epoch 7/9\n",
      "7982/7982 [==============================] - 1s 91us/step - loss: 0.4078 - accuracy: 0.8900 - val_loss: 1.2635 - val_accuracy: 0.7360\n",
      "Epoch 8/9\n",
      "7982/7982 [==============================] - 1s 92us/step - loss: 0.3910 - accuracy: 0.8926 - val_loss: 1.5898 - val_accuracy: 0.7450\n",
      "Epoch 9/9\n",
      "7982/7982 [==============================] - 1s 122us/step - loss: 0.2885 - accuracy: 0.9174 - val_loss: 1.3770 - val_accuracy: 0.7380\n",
      "2246/2246 [==============================] - 0s 187us/step\n",
      "[1.544305085498949, 0.7203918099403381]\n"
     ]
    }
   ],
   "source": [
    "# 5\n",
    "# 6개 유닛층 (256 유닛 수)\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(256, activation ='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(256, activation ='relu'))\n",
    "model.add(layers.Dense(256, activation ='relu'))\n",
    "model.add(layers.Dense(256, activation ='relu'))\n",
    "model.add(layers.Dense(256, activation ='relu'))\n",
    "model.add(layers.Dense(256, activation ='relu'))\n",
    "model.add(layers.Dense(46, activation ='softmax'))\n",
    "\n",
    "model.compile(optimizer = 'rmsprop',\n",
    "             loss = 'categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(partial_x_train,\n",
    "         partial_y_train,\n",
    "         epochs=9,\n",
    "         batch_size = 512,\n",
    "         validation_data = (x_val,y_val))\n",
    "results = model.evaluate(x_test,one_hot_test_labels)\n",
    "print(results)\n",
    "#72.03%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/9\n",
      "7982/7982 [==============================] - 1s 106us/step - loss: 2.4156 - accuracy: 0.3958 - val_loss: 1.7282 - val_accuracy: 0.5310\n",
      "Epoch 2/9\n",
      "7982/7982 [==============================] - 1s 90us/step - loss: 1.4479 - accuracy: 0.6480 - val_loss: 1.2659 - val_accuracy: 0.6950\n",
      "Epoch 3/9\n",
      "7982/7982 [==============================] - 1s 88us/step - loss: 1.0820 - accuracy: 0.7196 - val_loss: 1.2022 - val_accuracy: 0.7120\n",
      "Epoch 4/9\n",
      "7982/7982 [==============================] - 1s 87us/step - loss: 0.8656 - accuracy: 0.7750 - val_loss: 1.2586 - val_accuracy: 0.7130\n",
      "Epoch 5/9\n",
      "7982/7982 [==============================] - 1s 100us/step - loss: 0.7466 - accuracy: 0.8041 - val_loss: 1.1382 - val_accuracy: 0.7600\n",
      "Epoch 6/9\n",
      "7982/7982 [==============================] - 1s 93us/step - loss: 0.4950 - accuracy: 0.8693 - val_loss: 1.4534 - val_accuracy: 0.6690\n",
      "Epoch 7/9\n",
      "7982/7982 [==============================] - 1s 110us/step - loss: 0.4462 - accuracy: 0.8733 - val_loss: 1.1678 - val_accuracy: 0.7780\n",
      "Epoch 8/9\n",
      "7982/7982 [==============================] - 1s 107us/step - loss: 0.3800 - accuracy: 0.8940 - val_loss: 1.1740 - val_accuracy: 0.7950\n",
      "Epoch 9/9\n",
      "7982/7982 [==============================] - 1s 89us/step - loss: 0.3149 - accuracy: 0.9097 - val_loss: 1.3468 - val_accuracy: 0.7400\n",
      "2246/2246 [==============================] - 0s 141us/step\n",
      "[1.530185582270499, 0.7252894043922424]\n"
     ]
    }
   ],
   "source": [
    "# 6\n",
    "# 6개 유닛층 (256 유닛 수) - 점차 줄어듬\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(256, activation ='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(256, activation ='relu'))\n",
    "model.add(layers.Dense(256, activation ='relu'))\n",
    "model.add(layers.Dense(256, activation ='relu'))\n",
    "model.add(layers.Dense(128, activation ='relu'))\n",
    "model.add(layers.Dense(64, activation ='relu'))\n",
    "model.add(layers.Dense(46, activation ='softmax'))\n",
    "\n",
    "model.compile(optimizer = 'rmsprop',\n",
    "             loss = 'categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(partial_x_train,\n",
    "         partial_y_train,\n",
    "         epochs=9,\n",
    "         batch_size = 512,\n",
    "         validation_data = (x_val,y_val))\n",
    "results = model.evaluate(x_test,one_hot_test_labels)\n",
    "print(results)\n",
    "# 72.5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/9\n",
      "7982/7982 [==============================] - 3s 344us/step - loss: 2.0573 - accuracy: 0.5433 - val_loss: 1.2694 - val_accuracy: 0.6980\n",
      "Epoch 2/9\n",
      "7982/7982 [==============================] - 1s 101us/step - loss: 0.9850 - accuracy: 0.7760 - val_loss: 1.1290 - val_accuracy: 0.7180\n",
      "Epoch 3/9\n",
      "7982/7982 [==============================] - 1s 99us/step - loss: 0.6199 - accuracy: 0.8569 - val_loss: 1.2088 - val_accuracy: 0.7140\n",
      "Epoch 4/9\n",
      "7982/7982 [==============================] - 1s 105us/step - loss: 0.3706 - accuracy: 0.9141 - val_loss: 0.9418 - val_accuracy: 0.8080\n",
      "Epoch 5/9\n",
      "7982/7982 [==============================] - 1s 103us/step - loss: 0.3069 - accuracy: 0.9252 - val_loss: 0.9196 - val_accuracy: 0.8040\n",
      "Epoch 6/9\n",
      "7982/7982 [==============================] - 1s 100us/step - loss: 0.1862 - accuracy: 0.9508 - val_loss: 0.9736 - val_accuracy: 0.8000\n",
      "Epoch 7/9\n",
      "7982/7982 [==============================] - 1s 101us/step - loss: 0.1870 - accuracy: 0.9500 - val_loss: 1.1060 - val_accuracy: 0.7640\n",
      "Epoch 8/9\n",
      "7982/7982 [==============================] - 1s 132us/step - loss: 0.1402 - accuracy: 0.9568 - val_loss: 1.0004 - val_accuracy: 0.8010\n",
      "Epoch 9/9\n",
      "7982/7982 [==============================] - 1s 110us/step - loss: 0.1335 - accuracy: 0.9540 - val_loss: 1.0447 - val_accuracy: 0.7960\n",
      "2246/2246 [==============================] - 0s 143us/step\n",
      "[1.1882238182125617, 0.7809438705444336]\n"
     ]
    }
   ],
   "source": [
    "# 7\n",
    "# 4개 유닛층 (점점 줄어듬)\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(512, activation ='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(256, activation ='relu'))\n",
    "model.add(layers.Dense(128, activation ='relu'))\n",
    "model.add(layers.Dense(46, activation ='softmax'))\n",
    "\n",
    "model.compile(optimizer = 'rmsprop',\n",
    "             loss = 'categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(partial_x_train,\n",
    "         partial_y_train,\n",
    "         epochs=9,\n",
    "         batch_size = 512,\n",
    "         validation_data = (x_val,y_val))\n",
    "results = model.evaluate(x_test,one_hot_test_labels)\n",
    "print(results)\n",
    "# 78.09"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/9\n",
      "7982/7982 [==============================] - 1s 124us/step - loss: 1.5774 - accuracy: 0.6467 - val_loss: 1.1170 - val_accuracy: 0.7430\n",
      "Epoch 2/9\n",
      "7982/7982 [==============================] - 1s 113us/step - loss: 0.8015 - accuracy: 0.8207 - val_loss: 0.9924 - val_accuracy: 0.7760\n",
      "Epoch 3/9\n",
      "7982/7982 [==============================] - 1s 109us/step - loss: 0.4781 - accuracy: 0.8931 - val_loss: 0.9730 - val_accuracy: 0.7940\n",
      "Epoch 4/9\n",
      "7982/7982 [==============================] - 1s 109us/step - loss: 0.3043 - accuracy: 0.9320 - val_loss: 1.0919 - val_accuracy: 0.7940\n",
      "Epoch 5/9\n",
      "7982/7982 [==============================] - 1s 108us/step - loss: 0.2317 - accuracy: 0.9431 - val_loss: 1.2448 - val_accuracy: 0.7610\n",
      "Epoch 6/9\n",
      "7982/7982 [==============================] - 1s 118us/step - loss: 0.1901 - accuracy: 0.9500 - val_loss: 1.0206 - val_accuracy: 0.7940\n",
      "Epoch 7/9\n",
      "7982/7982 [==============================] - 1s 110us/step - loss: 0.1633 - accuracy: 0.9544 - val_loss: 1.2203 - val_accuracy: 0.7930\n",
      "Epoch 8/9\n",
      "7982/7982 [==============================] - 1s 113us/step - loss: 0.1435 - accuracy: 0.9549 - val_loss: 1.1916 - val_accuracy: 0.7850\n",
      "Epoch 9/9\n",
      "7982/7982 [==============================] - 1s 113us/step - loss: 0.1348 - accuracy: 0.9534 - val_loss: 1.1870 - val_accuracy: 0.8130\n",
      "2246/2246 [==============================] - 0s 127us/step\n",
      "[1.4229993769237217, 0.7809438705444336]\n"
     ]
    }
   ],
   "source": [
    "# 8\n",
    "# 3번 에서 batch 사이즈 변경\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(128, activation ='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(128, activation ='relu'))\n",
    "model.add(layers.Dense(128, activation ='relu'))\n",
    "model.add(layers.Dense(46, activation ='softmax'))\n",
    "\n",
    "model.compile(optimizer = 'rmsprop',\n",
    "             loss = 'categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(partial_x_train,\n",
    "         partial_y_train,\n",
    "         epochs=9,\n",
    "         batch_size = 128,\n",
    "         validation_data = (x_val,y_val))\n",
    "results = model.evaluate(x_test,one_hot_test_labels)\n",
    "print(results)\n",
    "# 78.09%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/9\n",
      "7982/7982 [==============================] - 2s 308us/step - loss: 3.0172 - accuracy: 0.3792 - val_loss: 2.0349 - val_accuracy: 0.5350\n",
      "Epoch 2/9\n",
      "7982/7982 [==============================] - 1s 80us/step - loss: 1.6398 - accuracy: 0.6443 - val_loss: 1.4006 - val_accuracy: 0.6810\n",
      "Epoch 3/9\n",
      "7982/7982 [==============================] - 1s 85us/step - loss: 1.1487 - accuracy: 0.7435 - val_loss: 1.1667 - val_accuracy: 0.7500\n",
      "Epoch 4/9\n",
      "7982/7982 [==============================] - 1s 84us/step - loss: 0.8164 - accuracy: 0.8170 - val_loss: 1.0177 - val_accuracy: 0.7810\n",
      "Epoch 5/9\n",
      "7982/7982 [==============================] - 1s 82us/step - loss: 0.5592 - accuracy: 0.8726 - val_loss: 0.9767 - val_accuracy: 0.8000\n",
      "Epoch 6/9\n",
      "7982/7982 [==============================] - 1s 82us/step - loss: 0.3815 - accuracy: 0.9158 - val_loss: 0.9609 - val_accuracy: 0.8080\n",
      "Epoch 7/9\n",
      "7982/7982 [==============================] - 1s 80us/step - loss: 0.2661 - accuracy: 0.9419 - val_loss: 0.9729 - val_accuracy: 0.8090\n",
      "Epoch 8/9\n",
      "7982/7982 [==============================] - 1s 83us/step - loss: 0.2014 - accuracy: 0.9505 - val_loss: 1.0256 - val_accuracy: 0.7990\n",
      "Epoch 9/9\n",
      "7982/7982 [==============================] - 1s 102us/step - loss: 0.1615 - accuracy: 0.9554 - val_loss: 1.0608 - val_accuracy: 0.8060\n",
      "2246/2246 [==============================] - 0s 171us/step\n",
      "[1.1454028352922556, 0.7858415246009827]\n"
     ]
    }
   ],
   "source": [
    "# 9\n",
    "# 3번에서 optimizer 변경 (adam)\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(128, activation ='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(128, activation ='relu'))\n",
    "model.add(layers.Dense(128, activation ='relu'))\n",
    "model.add(layers.Dense(46, activation ='softmax'))\n",
    "\n",
    "model.compile(optimizer = 'adam',\n",
    "             loss = 'categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(partial_x_train,\n",
    "         partial_y_train,\n",
    "         epochs=9,\n",
    "         batch_size = 512,\n",
    "         validation_data = (x_val,y_val))\n",
    "results = model.evaluate(x_test,one_hot_test_labels)\n",
    "print(results)\n",
    "# 78.58%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/12\n",
      "7982/7982 [==============================] - 1s 89us/step - loss: 3.5014 - accuracy: 0.3671 - val_loss: 2.8321 - val_accuracy: 0.5190\n",
      "Epoch 2/12\n",
      "7982/7982 [==============================] - 1s 78us/step - loss: 2.3429 - accuracy: 0.5441 - val_loss: 1.8416 - val_accuracy: 0.5860\n",
      "Epoch 3/12\n",
      "7982/7982 [==============================] - 1s 77us/step - loss: 1.6046 - accuracy: 0.6612 - val_loss: 1.4834 - val_accuracy: 0.6670\n",
      "Epoch 4/12\n",
      "7982/7982 [==============================] - 1s 80us/step - loss: 1.2789 - accuracy: 0.7182 - val_loss: 1.3015 - val_accuracy: 0.7160\n",
      "Epoch 5/12\n",
      "7982/7982 [==============================] - 1s 76us/step - loss: 1.0240 - accuracy: 0.7793 - val_loss: 1.1549 - val_accuracy: 0.7550\n",
      "Epoch 6/12\n",
      "7982/7982 [==============================] - 1s 76us/step - loss: 0.8121 - accuracy: 0.8274 - val_loss: 1.0707 - val_accuracy: 0.7750\n",
      "Epoch 7/12\n",
      "7982/7982 [==============================] - 1s 78us/step - loss: 0.6412 - accuracy: 0.8549 - val_loss: 1.0199 - val_accuracy: 0.7820\n",
      "Epoch 8/12\n",
      "7982/7982 [==============================] - 1s 78us/step - loss: 0.4973 - accuracy: 0.8851 - val_loss: 0.9854 - val_accuracy: 0.7980\n",
      "Epoch 9/12\n",
      "7982/7982 [==============================] - 1s 77us/step - loss: 0.3790 - accuracy: 0.9136 - val_loss: 0.9853 - val_accuracy: 0.8030\n",
      "Epoch 10/12\n",
      "7982/7982 [==============================] - 1s 75us/step - loss: 0.2873 - accuracy: 0.9332 - val_loss: 1.0000 - val_accuracy: 0.8040\n",
      "Epoch 11/12\n",
      "7982/7982 [==============================] - 1s 74us/step - loss: 0.2239 - accuracy: 0.9459 - val_loss: 1.0041 - val_accuracy: 0.8060\n",
      "Epoch 12/12\n",
      "7982/7982 [==============================] - 1s 78us/step - loss: 0.1817 - accuracy: 0.9523 - val_loss: 1.0393 - val_accuracy: 0.8090\n",
      "2246/2246 [==============================] - 0s 136us/step\n",
      "[1.1372739120136917, 0.7867319583892822]\n"
     ]
    }
   ],
   "source": [
    "# 10\n",
    "# batch_size up\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(128, activation ='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(128, activation ='relu'))\n",
    "model.add(layers.Dense(128, activation ='relu'))\n",
    "model.add(layers.Dense(46, activation ='softmax'))\n",
    "\n",
    "model.compile(optimizer = 'adam',\n",
    "             loss = 'categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(partial_x_train,\n",
    "         partial_y_train,\n",
    "         epochs=12,\n",
    "         batch_size = 1024,\n",
    "         validation_data = (x_val,y_val))\n",
    "results = model.evaluate(x_test,one_hot_test_labels)\n",
    "print(results)\n",
    "# 78.67"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\lee36\\lib\\site-packages\\keras\\datasets\\reuters.py:85: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
      "D:\\anaconda\\envs\\lee36\\lib\\site-packages\\keras\\datasets\\reuters.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    }
   ],
   "source": [
    "# 11 \n",
    "# 데이터 단어 30000만개\n",
    "(train_data_10, train_labels_10), (test_data_10, test_labels_10) = reuters.load_data(num_words=30000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_sequences_1(sequences, dimension=30000):\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequences in enumerate(sequences):\n",
    "        results[i, sequences]= 1.\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_1 = vectorize_sequences_1(train_data_10)\n",
    "x_test_1 = vectorize_sequences_1(test_data_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_train_labels_10 = to_categorical(train_labels_10)\n",
    "one_hot_test_labels_10 = to_categorical(test_labels_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val_1 = x_train_1[:1000]\n",
    "partial_x_train_1 = x_train_1[1000:]\n",
    "\n",
    "y_val_1= one_hot_train_labels_10[:1000]\n",
    "partial_y_train_1 = one_hot_train_labels_10[1000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/7\n",
      "7982/7982 [==============================] - 4s 442us/step - loss: 3.0972 - accuracy: 0.4783 - val_loss: 2.0244 - val_accuracy: 0.5590\n",
      "Epoch 2/7\n",
      "7982/7982 [==============================] - 2s 227us/step - loss: 1.5891 - accuracy: 0.6542 - val_loss: 1.3673 - val_accuracy: 0.6920\n",
      "Epoch 3/7\n",
      "7982/7982 [==============================] - 2s 260us/step - loss: 1.0644 - accuracy: 0.7549 - val_loss: 1.1243 - val_accuracy: 0.7490\n",
      "Epoch 4/7\n",
      "7982/7982 [==============================] - 2s 233us/step - loss: 0.7182 - accuracy: 0.8340 - val_loss: 1.0147 - val_accuracy: 0.7950\n",
      "Epoch 5/7\n",
      "7982/7982 [==============================] - 2s 233us/step - loss: 0.4602 - accuracy: 0.9013 - val_loss: 0.9848 - val_accuracy: 0.8000\n",
      "Epoch 6/7\n",
      "7982/7982 [==============================] - 2s 223us/step - loss: 0.2989 - accuracy: 0.9369 - val_loss: 1.0120 - val_accuracy: 0.8000\n",
      "Epoch 7/7\n",
      "7982/7982 [==============================] - 2s 266us/step - loss: 0.2103 - accuracy: 0.9491 - val_loss: 0.9984 - val_accuracy: 0.8070\n",
      "2246/2246 [==============================] - 1s 268us/step\n",
      "[1.0939733948117372, 0.7902938723564148]\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(128, activation ='relu', input_shape=(30000,)))\n",
    "model.add(layers.Dense(128, activation ='relu'))\n",
    "model.add(layers.Dense(128, activation ='relu'))\n",
    "model.add(layers.Dense(46, activation ='softmax'))\n",
    "\n",
    "model.compile(optimizer = 'adam',\n",
    "             loss = 'categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(partial_x_train_1,\n",
    "         partial_y_train_1,\n",
    "         epochs=7,\n",
    "         batch_size = 512,\n",
    "         validation_data = (x_val_1,y_val_1))\n",
    "results = model.evaluate(x_test_1,one_hot_test_labels_10)\n",
    "print(results)\n",
    "# 79.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/5\n",
      "7982/7982 [==============================] - 3s 436us/step - loss: 2.9475 - accuracy: 0.4226 - val_loss: 1.8176 - val_accuracy: 0.5700\n",
      "Epoch 2/5\n",
      "7982/7982 [==============================] - 3s 408us/step - loss: 1.5399 - accuracy: 0.6698 - val_loss: 1.3961 - val_accuracy: 0.6880\n",
      "Epoch 3/5\n",
      "7982/7982 [==============================] - 3s 379us/step - loss: 1.0876 - accuracy: 0.7499 - val_loss: 1.1644 - val_accuracy: 0.7400\n",
      "Epoch 4/5\n",
      "7982/7982 [==============================] - 3s 372us/step - loss: 0.7526 - accuracy: 0.8234 - val_loss: 1.0803 - val_accuracy: 0.7750\n",
      "Epoch 5/5\n",
      "7982/7982 [==============================] - 3s 436us/step - loss: 0.5050 - accuracy: 0.8777 - val_loss: 1.0715 - val_accuracy: 0.7810\n",
      "2246/2246 [==============================] - 1s 443us/step\n",
      "[1.1576800467388395, 0.7573463916778564]\n"
     ]
    }
   ],
   "source": [
    "# 12\n",
    "# 11 번 층 추가\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(128, activation ='relu', input_shape=(30000,)))\n",
    "model.add(layers.Dense(128, activation ='relu'))\n",
    "model.add(layers.Dense(128, activation ='relu'))\n",
    "model.add(layers.Dense(128, activation ='relu'))\n",
    "model.add(layers.Dense(46, activation ='softmax'))\n",
    "\n",
    "model.compile(optimizer = 'adam',\n",
    "             loss = 'categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(partial_x_train_1,\n",
    "         partial_y_train_1,\n",
    "         epochs=5,\n",
    "         batch_size = 512,\n",
    "         validation_data = (x_val_1,y_val_1))\n",
    "results = model.evaluate(x_test_1,one_hot_test_labels_10)\n",
    "print(results)\n",
    "# 75.73%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/5\n",
      "7982/7982 [==============================] - 3s 421us/step - loss: 1.9874 - accuracy: 0.5229 - val_loss: 1.3254 - val_accuracy: 0.6770\n",
      "Epoch 2/5\n",
      "7982/7982 [==============================] - 3s 437us/step - loss: 0.9575 - accuracy: 0.7737 - val_loss: 0.9822 - val_accuracy: 0.7870\n",
      "Epoch 3/5\n",
      "7982/7982 [==============================] - 3s 420us/step - loss: 0.5620 - accuracy: 0.8675 - val_loss: 0.9479 - val_accuracy: 0.7990\n",
      "Epoch 4/5\n",
      "7982/7982 [==============================] - 4s 458us/step - loss: 0.3480 - accuracy: 0.9222 - val_loss: 0.9002 - val_accuracy: 0.8130\n",
      "Epoch 5/5\n",
      "7982/7982 [==============================] - 3s 403us/step - loss: 0.2316 - accuracy: 0.9432 - val_loss: 0.9024 - val_accuracy: 0.8250\n",
      "2246/2246 [==============================] - 1s 468us/step\n",
      "[1.0037857034008946, 0.792965292930603]\n"
     ]
    }
   ],
   "source": [
    "# 13\n",
    "# 11 번 optimizer 변경\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(128, activation ='relu', input_shape=(30000,)))\n",
    "model.add(layers.Dense(128, activation ='relu'))\n",
    "model.add(layers.Dense(128, activation ='relu'))\n",
    "model.add(layers.Dense(46, activation ='softmax'))\n",
    "\n",
    "model.compile(optimizer = 'adagrad',\n",
    "             loss = 'categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(partial_x_train_1,\n",
    "         partial_y_train_1,\n",
    "         epochs=5,\n",
    "         batch_size = 512,\n",
    "         validation_data = (x_val_1,y_val_1))\n",
    "results = model.evaluate(x_test_1,one_hot_test_labels_10)\n",
    "print(results)\n",
    "# 79.29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/5\n",
      "7982/7982 [==============================] - 1s 156us/step - loss: 1.3469 - accuracy: 0.6957 - val_loss: 0.9709 - val_accuracy: 0.7830\n",
      "Epoch 2/5\n",
      "7982/7982 [==============================] - 1s 145us/step - loss: 0.6125 - accuracy: 0.8564 - val_loss: 0.8971 - val_accuracy: 0.8040\n",
      "Epoch 3/5\n",
      "7982/7982 [==============================] - 1s 169us/step - loss: 0.3437 - accuracy: 0.9202 - val_loss: 0.9095 - val_accuracy: 0.8180\n",
      "Epoch 4/5\n",
      "7982/7982 [==============================] - 1s 159us/step - loss: 0.2215 - accuracy: 0.9437 - val_loss: 0.9024 - val_accuracy: 0.8270\n",
      "Epoch 5/5\n",
      "7982/7982 [==============================] - 1s 145us/step - loss: 0.1683 - accuracy: 0.9518 - val_loss: 0.9592 - val_accuracy: 0.8200\n",
      "2246/2246 [==============================] - 0s 124us/step\n",
      "[1.0635837829229775, 0.7916295528411865]\n"
     ]
    }
   ],
   "source": [
    "# 14\n",
    "# 3번에서 optimizer/batch_size 변경 \n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(128, activation ='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(128, activation ='relu'))\n",
    "model.add(layers.Dense(128, activation ='relu'))\n",
    "model.add(layers.Dense(46, activation ='softmax'))\n",
    "\n",
    "model.compile(optimizer = 'adagrad',\n",
    "             loss = 'categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(partial_x_train,\n",
    "         partial_y_train,\n",
    "         epochs=5,\n",
    "         batch_size = 64,\n",
    "         validation_data = (x_val,y_val))\n",
    "results = model.evaluate(x_test,one_hot_test_labels)\n",
    "print(results)\n",
    "# 79.16%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/10\n",
      "7982/7982 [==============================] - 2s 253us/step - loss: 2.3953 - accuracy: 0.3903 - val_loss: 1.4944 - val_accuracy: 0.6410\n",
      "Epoch 2/10\n",
      "7982/7982 [==============================] - 2s 261us/step - loss: 1.2594 - accuracy: 0.7090 - val_loss: 1.2105 - val_accuracy: 0.7220\n",
      "Epoch 3/10\n",
      "7982/7982 [==============================] - 2s 265us/step - loss: 0.8836 - accuracy: 0.7856 - val_loss: 1.0909 - val_accuracy: 0.7520\n",
      "Epoch 4/10\n",
      "7982/7982 [==============================] - 2s 264us/step - loss: 0.5895 - accuracy: 0.8584 - val_loss: 1.0779 - val_accuracy: 0.7580\n",
      "Epoch 5/10\n",
      "7982/7982 [==============================] - 2s 252us/step - loss: 0.4135 - accuracy: 0.9083 - val_loss: 0.9577 - val_accuracy: 0.7960\n",
      "Epoch 6/10\n",
      "7982/7982 [==============================] - 2s 240us/step - loss: 0.2761 - accuracy: 0.9381 - val_loss: 0.9604 - val_accuracy: 0.8060\n",
      "Epoch 7/10\n",
      "7982/7982 [==============================] - 2s 240us/step - loss: 0.2003 - accuracy: 0.9496 - val_loss: 0.9440 - val_accuracy: 0.8160\n",
      "Epoch 8/10\n",
      "7982/7982 [==============================] - 2s 252us/step - loss: 0.1619 - accuracy: 0.9535 - val_loss: 0.9642 - val_accuracy: 0.8100\n",
      "Epoch 9/10\n",
      "7982/7982 [==============================] - 2s 239us/step - loss: 0.1406 - accuracy: 0.9550 - val_loss: 0.9844 - val_accuracy: 0.8130\n",
      "Epoch 10/10\n",
      "7982/7982 [==============================] - 2s 264us/step - loss: 0.1243 - accuracy: 0.9569 - val_loss: 0.9633 - val_accuracy: 0.8150\n",
      "2246/2246 [==============================] - 1s 410us/step\n",
      "[1.09799166396592, 0.7943009734153748]\n"
     ]
    }
   ],
   "source": [
    "# 15\n",
    "# 13 번 batchsize 변경\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(128, activation ='relu', input_shape=(30000,)))\n",
    "model.add(layers.Dense(128, activation ='relu'))\n",
    "model.add(layers.Dense(128, activation ='relu'))\n",
    "model.add(layers.Dense(46, activation ='softmax'))\n",
    "\n",
    "model.compile(optimizer = 'adagrad',\n",
    "             loss = 'categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(partial_x_train_1,\n",
    "         partial_y_train_1,\n",
    "         epochs=10,\n",
    "         batch_size = 1024,\n",
    "         validation_data = (x_val_1,y_val_1))\n",
    "results = model.evaluate(x_test_1,one_hot_test_labels_10)\n",
    "print(results)\n",
    "# 79.43%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/15\n",
      "7982/7982 [==============================] - 8s 998us/step - loss: 1.2541 - accuracy: 0.7088 - val_loss: 0.9345 - val_accuracy: 0.7810\n",
      "Epoch 2/15\n",
      "7982/7982 [==============================] - 8s 1ms/step - loss: 0.5835 - accuracy: 0.8532 - val_loss: 0.8843 - val_accuracy: 0.8110\n",
      "Epoch 3/15\n",
      "7982/7982 [==============================] - 8s 999us/step - loss: 0.3015 - accuracy: 0.9268 - val_loss: 0.8757 - val_accuracy: 0.8180\n",
      "Epoch 4/15\n",
      "7982/7982 [==============================] - 8s 995us/step - loss: 0.1898 - accuracy: 0.9503 - val_loss: 0.8811 - val_accuracy: 0.8150\n",
      "Epoch 5/15\n",
      "7982/7982 [==============================] - 8s 1ms/step - loss: 0.1410 - accuracy: 0.9539 - val_loss: 0.9856 - val_accuracy: 0.8180\n",
      "Epoch 6/15\n",
      "7982/7982 [==============================] - 8s 983us/step - loss: 0.1240 - accuracy: 0.9533 - val_loss: 0.9656 - val_accuracy: 0.8100\n",
      "Epoch 7/15\n",
      "7982/7982 [==============================] - 8s 1ms/step - loss: 0.1075 - accuracy: 0.9570 - val_loss: 1.0219 - val_accuracy: 0.8180\n",
      "Epoch 8/15\n",
      "7982/7982 [==============================] - 8s 1ms/step - loss: 0.0965 - accuracy: 0.9573 - val_loss: 1.0437 - val_accuracy: 0.8060\n",
      "Epoch 9/15\n",
      "7982/7982 [==============================] - 8s 979us/step - loss: 0.0926 - accuracy: 0.9551 - val_loss: 1.0527 - val_accuracy: 0.8060\n",
      "Epoch 10/15\n",
      "7982/7982 [==============================] - 8s 1ms/step - loss: 0.0872 - accuracy: 0.9550 - val_loss: 1.1154 - val_accuracy: 0.8030\n",
      "Epoch 11/15\n",
      "7982/7982 [==============================] - 8s 1ms/step - loss: 0.0847 - accuracy: 0.9570 - val_loss: 1.0634 - val_accuracy: 0.8140\n",
      "Epoch 12/15\n",
      "7982/7982 [==============================] - 8s 986us/step - loss: 0.0792 - accuracy: 0.9590 - val_loss: 1.0823 - val_accuracy: 0.8050\n",
      "Epoch 13/15\n",
      "7982/7982 [==============================] - 8s 1ms/step - loss: 0.0773 - accuracy: 0.9565 - val_loss: 1.1230 - val_accuracy: 0.8080\n",
      "Epoch 14/15\n",
      "7982/7982 [==============================] - 8s 1ms/step - loss: 0.0759 - accuracy: 0.9569 - val_loss: 1.1047 - val_accuracy: 0.8170\n",
      "Epoch 15/15\n",
      "7982/7982 [==============================] - 8s 1ms/step - loss: 0.0728 - accuracy: 0.9588 - val_loss: 1.1668 - val_accuracy: 0.8040\n",
      "2246/2246 [==============================] - 1s 360us/step\n",
      "[1.3215813014725968, 0.7956367135047913]\n"
     ]
    }
   ],
   "source": [
    "# 16\n",
    "# 15번에서 batch size / 유닛 수 변경\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(256, activation ='relu', input_shape=(30000,)))\n",
    "model.add(layers.Dense(256, activation ='relu'))\n",
    "model.add(layers.Dense(256, activation ='relu'))\n",
    "model.add(layers.Dense(46, activation ='softmax'))\n",
    "\n",
    "model.compile(optimizer = 'adagrad',\n",
    "             loss = 'categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(partial_x_train_1,\n",
    "         partial_y_train_1,\n",
    "         epochs=15,\n",
    "         batch_size = 16,\n",
    "         validation_data = (x_val_1,y_val_1))\n",
    "results = model.evaluate(x_test_1,one_hot_test_labels_10)\n",
    "print(results)\n",
    "# 79.56%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/15\n",
      "7982/7982 [==============================] - 14s 2ms/step - loss: 1.2558 - accuracy: 0.7105 - val_loss: 0.9263 - val_accuracy: 0.7840\n",
      "Epoch 2/15\n",
      "7982/7982 [==============================] - 8s 1ms/step - loss: 0.5769 - accuracy: 0.8547 - val_loss: 0.8400 - val_accuracy: 0.8070\n",
      "Epoch 3/15\n",
      "7982/7982 [==============================] - 9s 1ms/step - loss: 0.3116 - accuracy: 0.9217 - val_loss: 0.8640 - val_accuracy: 0.8100\n",
      "Epoch 4/15\n",
      "7982/7982 [==============================] - 8s 1ms/step - loss: 0.1945 - accuracy: 0.9453 - val_loss: 0.9335 - val_accuracy: 0.8060\n",
      "Epoch 5/15\n",
      "7982/7982 [==============================] - 8s 1ms/step - loss: 0.1465 - accuracy: 0.9531 - val_loss: 0.9484 - val_accuracy: 0.8110\n",
      "Epoch 6/15\n",
      "7982/7982 [==============================] - 8s 1ms/step - loss: 0.1210 - accuracy: 0.9551 - val_loss: 0.9598 - val_accuracy: 0.8170\n",
      "Epoch 7/15\n",
      "7982/7982 [==============================] - 8s 966us/step - loss: 0.1073 - accuracy: 0.9564 - val_loss: 1.0306 - val_accuracy: 0.8140\n",
      "Epoch 8/15\n",
      "7982/7982 [==============================] - 8s 997us/step - loss: 0.0959 - accuracy: 0.9572 - val_loss: 1.0430 - val_accuracy: 0.8050\n",
      "Epoch 9/15\n",
      "7982/7982 [==============================] - 8s 999us/step - loss: 0.0908 - accuracy: 0.9584 - val_loss: 1.0470 - val_accuracy: 0.8110\n",
      "Epoch 10/15\n",
      "7982/7982 [==============================] - 8s 974us/step - loss: 0.0854 - accuracy: 0.9564 - val_loss: 1.0571 - val_accuracy: 0.8130\n",
      "Epoch 11/15\n",
      "7982/7982 [==============================] - 8s 1ms/step - loss: 0.0817 - accuracy: 0.9563 - val_loss: 1.0746 - val_accuracy: 0.8140\n",
      "Epoch 12/15\n",
      "7982/7982 [==============================] - 8s 978us/step - loss: 0.0791 - accuracy: 0.9575 - val_loss: 1.0946 - val_accuracy: 0.8120\n",
      "Epoch 13/15\n",
      "7982/7982 [==============================] - 8s 983us/step - loss: 0.0765 - accuracy: 0.9574 - val_loss: 1.1204 - val_accuracy: 0.8120\n",
      "Epoch 14/15\n",
      "7982/7982 [==============================] - 8s 1ms/step - loss: 0.0739 - accuracy: 0.9574 - val_loss: 1.1634 - val_accuracy: 0.8130\n",
      "Epoch 15/15\n",
      "7982/7982 [==============================] - 8s 1000us/step - loss: 0.0725 - accuracy: 0.9582 - val_loss: 1.1611 - val_accuracy: 0.8180\n",
      "2246/2246 [==============================] - 1s 514us/step\n",
      "[1.373000508849364, 0.7898486256599426]\n",
      "time : 129.69543290138245\n"
     ]
    }
   ],
   "source": [
    "# cpu gpu time 비교\n",
    "# cpu\n",
    "start = time.time() \n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(256, activation ='relu', input_shape=(30000,)))\n",
    "model.add(layers.Dense(256, activation ='relu'))\n",
    "model.add(layers.Dense(256, activation ='relu'))\n",
    "model.add(layers.Dense(46, activation ='softmax'))\n",
    "\n",
    "model.compile(optimizer = 'adagrad',\n",
    "             loss = 'categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(partial_x_train_1,\n",
    "         partial_y_train_1,\n",
    "         epochs=15,\n",
    "         batch_size = 16,\n",
    "         validation_data = (x_val_1,y_val_1))\n",
    "results = model.evaluate(x_test_1,one_hot_test_labels_10)\n",
    "print(results)\n",
    "print(\"time :\", time.time() - start)\n",
    "# 79.56%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/15\n",
      "7982/7982 [==============================] - 9s 1ms/step - loss: 1.2742 - accuracy: 0.7092 - val_loss: 0.9613 - val_accuracy: 0.7820\n",
      "Epoch 2/15\n",
      "7982/7982 [==============================] - 9s 1ms/step - loss: 0.5781 - accuracy: 0.8581 - val_loss: 0.8603 - val_accuracy: 0.8220\n",
      "Epoch 3/15\n",
      "7982/7982 [==============================] - 9s 1ms/step - loss: 0.3098 - accuracy: 0.9225 - val_loss: 0.8821 - val_accuracy: 0.8110\n",
      "Epoch 4/15\n",
      "7982/7982 [==============================] - 8s 1ms/step - loss: 0.1995 - accuracy: 0.9453 - val_loss: 0.9375 - val_accuracy: 0.8150\n",
      "Epoch 5/15\n",
      "7982/7982 [==============================] - 10s 1ms/step - loss: 0.1468 - accuracy: 0.9525 - val_loss: 0.9589 - val_accuracy: 0.8100\n",
      "Epoch 6/15\n",
      "7982/7982 [==============================] - 10s 1ms/step - loss: 0.1210 - accuracy: 0.9555 - val_loss: 1.0020 - val_accuracy: 0.8040\n",
      "Epoch 7/15\n",
      "3968/7982 [=============>................] - ETA: 5s - loss: 0.0890 - accuracy: 0.9667 - "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-49-15480d5753cf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m              \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m              \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m              validation_data = (x_val_1,y_val_1))\n\u001b[0m\u001b[0;32m     21\u001b[0m     \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test_1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mone_hot_test_labels_10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\lee36\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[0;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[1;32mD:\\anaconda\\envs\\lee36\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[0;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\lee36\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3725\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3726\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3727\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3728\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3729\u001b[0m     \u001b[1;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\lee36\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1549\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1550\u001b[0m     \"\"\"\n\u001b[1;32m-> 1551\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1552\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1553\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\lee36\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1589\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[0;32m   1590\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[1;32m-> 1591\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1592\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1593\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\lee36\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\lee36\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mD:\\anaconda\\envs\\lee36\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# gpu\n",
    "import tensorflow as tf\n",
    "#tf.debugging.set_log_device_placement(True)\n",
    "start = time.time() \n",
    "with tf.device('/GPU:0'):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(256, activation ='relu', input_shape=(30000,)))\n",
    "    model.add(layers.Dense(256, activation ='relu'))\n",
    "    model.add(layers.Dense(256, activation ='relu'))\n",
    "    model.add(layers.Dense(46, activation ='softmax'))\n",
    "\n",
    "    model.compile(optimizer = 'adagrad',\n",
    "                 loss = 'categorical_crossentropy',\n",
    "                 metrics=['accuracy'])\n",
    "\n",
    "    model.fit(partial_x_train_1,\n",
    "             partial_y_train_1,\n",
    "             epochs=15,\n",
    "             batch_size = 16,\n",
    "             validation_data = (x_val_1,y_val_1))\n",
    "    results = model.evaluate(x_test_1,one_hot_test_labels_10)\n",
    "    print(results)\n",
    "    print(\"time :\", time.time() - start)\n",
    "# 79.56%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 13545084556140119658\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 3142752667\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 18157627720634403590\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1050, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow_core._api.v2.config' has no attribute 'experimental_list_devices'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-73936b46986e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensorflow_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_available_gpus\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\anaconda\\envs\\lee36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_get_available_gpus\u001b[1;34m()\u001b[0m\n\u001b[0;32m    504\u001b[0m             \u001b[0m_LOCAL_DEVICES\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdevices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    505\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 506\u001b[1;33m             \u001b[0m_LOCAL_DEVICES\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_list_devices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    507\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_LOCAL_DEVICES\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;34m'device:gpu'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    508\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow_core._api.v2.config' has no attribute 'experimental_list_devices'"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-28-ebb74ce83619>:3: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available(\n",
    "    cuda_only=False,\n",
    "    min_cuda_compute_capability=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.1'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow_core._api.v2.config' has no attribute 'experimental_list_devices'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-eb8f9dc10472>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensorflow_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_available_gpus\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\anaconda\\envs\\lee36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_get_available_gpus\u001b[1;34m()\u001b[0m\n\u001b[0;32m    504\u001b[0m             \u001b[0m_LOCAL_DEVICES\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdevices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    505\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 506\u001b[1;33m             \u001b[0m_LOCAL_DEVICES\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_list_devices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    507\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_LOCAL_DEVICES\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;34m'device:gpu'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    508\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow_core._api.v2.config' has no attribute 'experimental_list_devices'"
     ]
    }
   ],
   "source": [
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "[python36.x]",
   "language": "python",
   "name": "lee36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
